## Лабораторная работа № 4

Задание:
1. Модель должна научиться классифицировать текст
2. Должны выполнены три реализации модели. Реализации должны быть основаны на использовании:
    - одномерной сверточной нейросети
    - рекуррентной нейросети LSTM
    - рекуррентной нейросети GRU
3. Выполнить сравнение полученных результатов и сделать вывод

Исходные данные:
- для обучения: https://github.com/mhjabreel/CharCnn_Keras/raw/master/data/ag_news_csv/train.csv
- для тестирования: https://github.com/mhjabreel/CharCnn_Keras/raw/master/data/ag_news_csv/test.csv
- имена классов: https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/classes.txt

## Результаты

Accuracy
![accuracy](images/accuracy.png)

Loss
![accuracy](images/loss.png)

|Модель  |Время обучения  |Тестовая точность  |Комментарии|
|-------|----------------|-------------------|------------|
|1D-CNN  |Быстро  |90.66%  |Высокая точность, минимальное время.|
|LSTM  |Медленно  |89.16%  |Требуется больше эпох для оптимизации.|
|GRU  |Средне  |90.62%  |Хороший баланс точности и времени.|

Выводы:
* Если приоритетом является скорость обучения и высокая точность: использовать 1D-CNN
* Если требуется лучшая обработка временной зависимости текста: использовать GRU (вместо LSTM, так как GRU обучается быстрее и показывает аналогичные результаты)
* Если точность ниже 90% критична: рассмотреть увеличение числа эпох для LSTM/GRU или эксперименты с гиперпараметрами